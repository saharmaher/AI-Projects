{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f858631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb81ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos=pd.read_csv('train_Arabic_tweets_positive_20190413.tsv',delimiter='\\t',names=['label','tweet'])\n",
    "train_neg=pd.read_csv('train_Arabic_tweets_negative_20190413.tsv',delimiter='\\t',names=['label','tweet'])\n",
    "\n",
    "test_pos=pd.read_csv('test_Arabic_tweets_positive_20190413.tsv',delimiter='\\t',names=['label','tweet'])\n",
    "test_neg=pd.read_csv('test_Arabic_tweets_negative_20190413.tsv',delimiter='\\t',names=['label','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22bc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281298c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd011119",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('arabic')\n",
    "st = ISRIStemmer()\n",
    "stop=[]\n",
    "for w in stopwords_list:\n",
    "    rootWord=st.stem(w)\n",
    "    stop.append(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bb330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([train_neg,train_pos],axis=0,ignore_index=True)\n",
    "\n",
    "test=pd.concat([test_neg,test_pos],axis=0)\n",
    "s=train['tweet'].str.len()\n",
    "train_neg=[]\n",
    "train_pos=[]\n",
    "test_pos=[]\n",
    "test_neg=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885134c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    stemmer = nltk.ISRIStemmer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    #remove arabic stopwords\n",
    "    word_list = [ w for w in word_list if not w in stopwords_list ]\n",
    "    #remove digits\n",
    "    word_list = [ w for w in word_list ]\n",
    "    #stemming\n",
    "    word_list = [stemmer.stem(w) for w in  word_list]\n",
    "    return ' '.join(word_list) \n",
    "\n",
    "\n",
    "def clean_text(text):  \n",
    "\n",
    "    search = [\"Ø£\",\"Ø¥\",\"Ø¢\",\"Ø©\",\"_\",\"-\",\"/\",\".\",\"ØŒ\",\" Ùˆ \",\" ÙŠØ§ \",'\"',\"Ù€\",\"'\",\"Ù‰\",\n",
    "              \"\\\\\",'\\n', '\\t','&quot;','?','ØŸ','!']\n",
    "    replace = [\"Ø§\",\"Ø§\",\"Ø§\",\"Ù‡\",\" \",\" \",\"\",\"\",\"\",\" Ùˆ\",\" ÙŠØ§\",\n",
    "               \"\",\"\",\"\",\"ÙŠ\",\"\",' ', ' ',' ',' ? ',' ØŸ ', ' ! ']\n",
    "    #remove tashkeel\n",
    "    tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(tashkeel,\"\", text)\n",
    "  \n",
    "    longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(longation, subst, text)\n",
    "    \n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "    #remove english words\n",
    "    text = re.sub(r\"[a-zA-Z]\", '', text)\n",
    "    #remove spaces\n",
    "    text = re.sub(r\"\\d+\", ' ', text)\n",
    "    text = re.sub(r\"\\n+\", ' ', text)\n",
    "    text = re.sub(r\"\\t+\", ' ', text)\n",
    "    text = re.sub(r\"\\r+\", ' ', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    #remove repetetions\n",
    "    text = text.replace('ÙˆÙˆ', 'Ùˆ')\n",
    "    text = text.replace('ÙŠÙŠ', 'ÙŠ')\n",
    "    text = text.replace('Ø§Ø§', 'Ø§')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return process_text(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22274970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326cf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet2']=train.tweet.apply(clean_text)\n",
    "test['tweet2']=test.tweet.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69facd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...</td>\n",
       "      <td>Ø¹Ø±Ù Ø§Ù† Ø¨ØªØ³ ÙƒÙ†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ Ø¬ÙŠØ¨Ùˆ Ø±Ø³ÙŠ Ø§Ù„ÙŠÙˆÙ… Ø²ÙŠØ¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...</td>\n",
       "      <td>ÙˆÙ‚Ø¹ Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø± Ø¨Ø´Ù ÙƒÙ…Ù„ Ø­ÙŠÙ† Ø§Ø­Ø³ Ø§Ø­Ø¯ Ù†Ù‚Øµ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>#Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§ÙƒØªØ¨ ØªÙˆÙ‚Ø¹Ùƒ Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‡Ù„Ø§Ù„ Ùˆ...</td>\n",
       "      <td>Ø§Ù‡Ù„ Ù‡Ù„Ù„ ÙƒØªØ¨ ÙˆÙ‚Ø¹ Ù†ØªØ¬ Ù„Ù‚Ø¡ Ù‡Ù„Ù„ Ø§Ù‡Ù„ ØªØ§Ù‚ ØªØ­Ø¯ Ø³Ø±Ø¹ Ø±Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ù†Ø¹Ù…Ø© Ø§Ù„Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø­ÙŠÙˆÙŠØ© . ØªØ¶Ø¹ Ù‚Ø·Ø±Ø©ğŸ’§Ù…Ø¶Ø§Ø¯ Ø¨Ù†Ø³Ù„ÙŠÙ† Ø¹...</td>\n",
       "      <td>Ù†Ø¹Ù… Ø¶Ø§Ø¯ Ø­ÙŠÙŠ ØªØ¶Ø¹ Ù‚Ø·Ø±Ù‡Ù…Ø¶Ø§Ø¯ Ù†Ø³Ù„ Ø¹Ù„ÙŠ ÙƒØªØ± ÙØ¬Ø± ØªÙ…Ùˆ Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ù„Ø¯ÙˆØ¯Ùˆ Ø¬Ø§ÙŠÙ‡ ØªÙƒÙ…Ù„ Ø¹Ù„ÙŠ ğŸ’”</td>\n",
       "      <td>Ø¯ÙˆØ¯Ùˆ Ø¬ÙŠÙ‡ ÙƒÙ…Ù„ Ø¹Ù„ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45270</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù„ÙŠÙ„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§ÙŠÙÙˆÙ† .. Ø±ØªÙˆÙŠØª Ù„Ù„Ù…Ø±ÙÙ‚Ø© ÙˆØ·Ø¨Ù‚...</td>\n",
       "      <td>Ø³Ø­Ø¨ Ù„ÙŠÙ„ Ø¹Ù„ÙŠ Ø§ÙŠÙ Ø±ØªÙŠ Ø±ÙÙ‚ Ø·Ø¨Ù‚ Ø´Ø±Ø·</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45271</th>\n",
       "      <td>pos</td>\n",
       "      <td>ğŸ˜‚ Ù„Ø§Ø¨Ø³Ø© Ø§Ø­Ù…Ø± Ù„ÙŠÙ‡ ÙŠØ§ Ø³Øª Ø§Ù†ØªÙŠ Ø§ÙŠÙ‡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ğŸ˜‚</td>\n",
       "      <td>Ù„Ø¨Ø³ Ø­Ù…Ø± Ù„ÙŠÙ‡ ÙŠØ³Øª Ø§Ù†Øª Ø§ÙŠÙ‡ Ù†Ø³Ø¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45272</th>\n",
       "      <td>pos</td>\n",
       "      <td>ÙƒÙ„Ø§Ø§Ù… Ø¬Ù…ÙŠÙŠÙ„ ØªØ³ØªØ§Ù‡Ù„(Ù…Ù† Ø§Ø­Ø¨Ù‡ Ø§Ù„Ù„Ù‡ Ø¬Ø¹Ù„ Ù…Ø­Ø¨ØªÙ‡ Ù Ù‚Ù„...</td>\n",
       "      <td>ÙƒÙ„Ù… Ø¬Ù…Ù„ ØªØ³ØªØ§Ù‡Ù„Ù…Ù† Ø§Ø­Ø¨ Ø§Ù„Ù„ Ø­Ø¨Øª Ù‚Ù„Ø¨ Ø¨Ø´Ø±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45273</th>\n",
       "      <td>pos</td>\n",
       "      <td>- Ø£Ù„Ø·Ù ØµÙˆØ±Ø© Ù…Ù…ÙƒÙ† ØªØ¹Ø¨Ø± Ø¹Ù† Ø±Ù…Ø¶Ø§Ù† ğŸ’™</td>\n",
       "      <td>Ù„Ø·Ù ØµÙˆØ± Ù…ÙƒÙ† Ø¹Ø¨Ø± Ø±Ù…Ø¶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45274</th>\n",
       "      <td>pos</td>\n",
       "      <td>ğŸŒ¸ Ù‚Ø§Ù„ #Ø§Ù„Ø¥Ù…Ø§Ù…_Ø§Ø¨Ù†_Ø§Ù„Ù‚ÙŠÙ… -Ø±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰- : - ...</td>\n",
       "      <td>Ù‚Ø§Ù„ Ø§Ù…Ù… Ø§Ø¨Ù† Ù‚ÙŠÙ… Ø±Ø­Ù… Ø§Ù„Ù„ Ø¹Ù„ÙŠ ÙØ§Ù† ÙŠØ± Ù†Ø¹Ù… Ø§Ù„Ù„ Ø§Ù„Ø§...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45275 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet  \\\n",
       "0       neg  Ø§Ø¹ØªØ±Ù Ø§Ù† Ø¨ØªØ³ ÙƒØ§Ù†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ ÙŠØ¬ÙŠØ¨Ùˆ Ø±Ø§Ø³ÙŠ Ù„ÙƒÙ† Ø§Ù„ÙŠÙˆÙ…...   \n",
       "1       neg  ØªÙˆÙ‚Ø¹Øª Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø±ÙŠØ§ Ø¨Ø´ÙˆÙÙ‡Ù… ÙƒØ§Ù…Ù„ÙŠÙ† Ø¨Ø³ Ù„ÙŠ Ù„Ù„Ø­ÙŠÙ† ...   \n",
       "2       neg  #Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§ÙƒØªØ¨ ØªÙˆÙ‚Ø¹Ùƒ Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‡Ù„Ø§Ù„ Ùˆ...   \n",
       "3       neg  Ù†Ø¹Ù…Ø© Ø§Ù„Ù…Ø¶Ø§Ø¯Ø§Øª Ø§Ù„Ø­ÙŠÙˆÙŠØ© . ØªØ¶Ø¹ Ù‚Ø·Ø±Ø©ğŸ’§Ù…Ø¶Ø§Ø¯ Ø¨Ù†Ø³Ù„ÙŠÙ† Ø¹...   \n",
       "4       neg                             Ø§Ù„Ø¯ÙˆØ¯Ùˆ Ø¬Ø§ÙŠÙ‡ ØªÙƒÙ…Ù„ Ø¹Ù„ÙŠ ğŸ’”   \n",
       "...     ...                                                ...   \n",
       "45270   pos  Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù„ÙŠÙ„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§ÙŠÙÙˆÙ† .. Ø±ØªÙˆÙŠØª Ù„Ù„Ù…Ø±ÙÙ‚Ø© ÙˆØ·Ø¨Ù‚...   \n",
       "45271   pos         ğŸ˜‚ Ù„Ø§Ø¨Ø³Ø© Ø§Ø­Ù…Ø± Ù„ÙŠÙ‡ ÙŠØ§ Ø³Øª Ø§Ù†ØªÙŠ Ø§ÙŠÙ‡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ğŸ˜‚   \n",
       "45272   pos  ÙƒÙ„Ø§Ø§Ù… Ø¬Ù…ÙŠÙŠÙ„ ØªØ³ØªØ§Ù‡Ù„(Ù…Ù† Ø§Ø­Ø¨Ù‡ Ø§Ù„Ù„Ù‡ Ø¬Ø¹Ù„ Ù…Ø­Ø¨ØªÙ‡ Ù Ù‚Ù„...   \n",
       "45273   pos                   - Ø£Ù„Ø·Ù ØµÙˆØ±Ø© Ù…Ù…ÙƒÙ† ØªØ¹Ø¨Ø± Ø¹Ù† Ø±Ù…Ø¶Ø§Ù† ğŸ’™   \n",
       "45274   pos  ğŸŒ¸ Ù‚Ø§Ù„ #Ø§Ù„Ø¥Ù…Ø§Ù…_Ø§Ø¨Ù†_Ø§Ù„Ù‚ÙŠÙ… -Ø±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰- : - ...   \n",
       "\n",
       "                                                  tweet2  \n",
       "0              Ø¹Ø±Ù Ø§Ù† Ø¨ØªØ³ ÙƒÙ†Ùˆ Ø´ÙˆÙŠ Ø´ÙˆÙŠ Ø¬ÙŠØ¨Ùˆ Ø±Ø³ÙŠ Ø§Ù„ÙŠÙˆÙ… Ø²ÙŠØ¯  \n",
       "1                ÙˆÙ‚Ø¹ Ø§Ø°Ø§ Ø¬Ø§Øª Ø¯Ø§Ø± Ø¨Ø´Ù ÙƒÙ…Ù„ Ø­ÙŠÙ† Ø§Ø­Ø³ Ø§Ø­Ø¯ Ù†Ù‚Øµ  \n",
       "2      Ø§Ù‡Ù„ Ù‡Ù„Ù„ ÙƒØªØ¨ ÙˆÙ‚Ø¹ Ù†ØªØ¬ Ù„Ù‚Ø¡ Ù‡Ù„Ù„ Ø§Ù‡Ù„ ØªØ§Ù‚ ØªØ­Ø¯ Ø³Ø±Ø¹ Ø±Ùˆ...  \n",
       "3      Ù†Ø¹Ù… Ø¶Ø§Ø¯ Ø­ÙŠÙŠ ØªØ¶Ø¹ Ù‚Ø·Ø±Ù‡Ù…Ø¶Ø§Ø¯ Ù†Ø³Ù„ Ø¹Ù„ÙŠ ÙƒØªØ± ÙØ¬Ø± ØªÙ…Ùˆ Ø§...  \n",
       "4                                       Ø¯ÙˆØ¯Ùˆ Ø¬ÙŠÙ‡ ÙƒÙ…Ù„ Ø¹Ù„ÙŠ  \n",
       "...                                                  ...  \n",
       "45270                    Ø³Ø­Ø¨ Ù„ÙŠÙ„ Ø¹Ù„ÙŠ Ø§ÙŠÙ Ø±ØªÙŠ Ø±ÙÙ‚ Ø·Ø¨Ù‚ Ø´Ø±Ø·  \n",
       "45271                        Ù„Ø¨Ø³ Ø­Ù…Ø± Ù„ÙŠÙ‡ ÙŠØ³Øª Ø§Ù†Øª Ø§ÙŠÙ‡ Ù†Ø³Ø¨  \n",
       "45272               ÙƒÙ„Ù… Ø¬Ù…Ù„ ØªØ³ØªØ§Ù‡Ù„Ù…Ù† Ø§Ø­Ø¨ Ø§Ù„Ù„ Ø­Ø¨Øª Ù‚Ù„Ø¨ Ø¨Ø´Ø±  \n",
       "45273                                Ù„Ø·Ù ØµÙˆØ± Ù…ÙƒÙ† Ø¹Ø¨Ø± Ø±Ù…Ø¶  \n",
       "45274  Ù‚Ø§Ù„ Ø§Ù…Ù… Ø§Ø¨Ù† Ù‚ÙŠÙ… Ø±Ø­Ù… Ø§Ù„Ù„ Ø¹Ù„ÙŠ ÙØ§Ù† ÙŠØ± Ù†Ø¹Ù… Ø§Ù„Ù„ Ø§Ù„Ø§...  \n",
       "\n",
       "[45275 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d63d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.tweet\n",
    "X_test=test.tweet\n",
    "y_train=train['label']\n",
    "y_test=test['label']\n",
    "train=[]\n",
    "\n",
    "X_train.drop_duplicates()\n",
    "\n",
    "enc=LabelEncoder()\n",
    "y_train=enc.fit_transform(y_train)\n",
    "y_test=enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a490a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 78651\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print(\"vocab size:\",len(tokenizer.word_index))\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=300)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be043e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          2000000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300, 200)         160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 200)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               25728     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,196,897\n",
      "Trainable params: 2,196,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create LSTM model with keras\n",
    "embedding_dim = 100\n",
    "dropout = 0.5\n",
    "opt = 'adam'\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=20000, \n",
    "                           output_dim=100, \n",
    "                           input_length=300))\n",
    "model.add(layers.Bidirectional(layers.LSTM(100, dropout=0.5, \n",
    "                                           recurrent_dropout=0.5, \n",
    "                                           return_sequences=True)))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "177/177 [==============================] - 8199s 46s/step - loss: 0.5197 - accuracy: 0.6877\n",
      "Epoch 2/4\n",
      " 29/177 [===>..........................] - ETA: 1:03:59 - loss: 0.1701 - accuracy: 0.9440"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=4,\n",
    "                    verbose=True,\n",
    "                    validation_freq=0.2,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231fdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf065b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
